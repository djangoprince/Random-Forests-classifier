from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
import numpy as np
import math
import copy

class rf:
    def __init__(self, n_trees, n_splitvars):
        self.n_trees = n_trees           # Number of trees in the forest 100
        self.n_splitvars = n_splitvars   # Size of subset of variables considered for each node split
        self.n_classes = None            # Number of classes
        self.forest = []                 # List of decision trees

    def train(self, X, y):
        # Input:
        #   X            n by p matrix of input values (a.k.a. features, attributes)
        #   y            n-vector of class labels on the form 0,1,...,(n_classes-1)
        self.n_classes = len(np.unique(y))
        
       # Load the data
        #X=np.genfromtxt('rental.csv', delimiter=',', skip_header=1) #generation data
        sample = np.random.randint(X, size=(100,self.n_splitvars))
        X_train, X_test, y_train, y_test = train_test_split(sample.data, sample.target, test_size=0.33, random_state=42)
        clf = DecisionTreeClassifier(splitter='random',max_features=self.n_splitvars)
        clf = clf.fit(X_train, y_train)
        #max_features=sqrt(n_features)


            
    def predict(self, X_test):
        # Input:
        #   X            n by p matrix containing samples to predict
        # Returns:
        #   ypred        Predictions, labels on the form 0,1,...,(n_classes-1)
        X1 = copy.deepcopy(X_test)
        y_pred = clf.predict(X1)

        return y_pred
    
#test
n_trees=100
nfeatures=1000
n_splitvars=math.sqrt(nfeatures)
X=np.genfromtxt('rental.csv', delimiter=',', skip_header=1)
s= rf(n_trees,n_splitvars)
#for i in range(1,100):
s.train(X,X[1])
s.predict(X_test)
test_error = np.average(y != y_pred)
print("Test set error rate: {:1.3f}".format(test_error))
training_error = np.average(X != X_test)
print("Training set error rate: {:1.3f}".format(training_error))
